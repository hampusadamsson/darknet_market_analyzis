{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import itertools\n",
    "import matplotlib\n",
    "from time import time\n",
    "# from pandas.tools.plotting import table\n",
    "import time\n",
    "import os\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import f1_score, adjusted_rand_score, accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from copy import copy\n",
    "from sklearn.decomposition import PCA, TruncatedSVD, SparsePCA\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.decomposition import PCA, NMF, IncrementalPCA, FastICA, LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.manifold import Isomap, MDS, LocallyLinearEmbedding, TSNE\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "\n",
    "# plt.style.use(\"ggplot\")\n",
    "plt.style.use('default')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alphabay : 15222 samples, \n",
      " 12 mains,  48 subs\n",
      "poseidon : 3688 samples, \n",
      " 10 mains,  36 subs\n",
      "silkroad : 2137 samples, \n",
      " 1 mains,  22 subs\n"
     ]
    }
   ],
   "source": [
    "category = {}\n",
    "category_sub = {}\n",
    "description = {}\n",
    "\n",
    "for nm in [\"alphabay\", \"poseidon\", \"silkroad\"]:\n",
    "    description[nm], category[nm], category_sub[nm] = pickle.load(open(\"data/meta/{}_dataset.p\".format(nm), \"rb\"))    \n",
    "    print(nm, \":\", len(description[nm]), \"samples, \\n\", len(set(category[nm])),\"mains, \", len(set(category_sub[nm])), \"subs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# reduce dimension\n",
    "# Input: input, output_dimension \n",
    "# Out:   X, reduction_object\n",
    "#\n",
    "\n",
    "\n",
    "def red_dim(inp, dim_out, domain_bypass=False, norm=False):\n",
    "    master_ = 3000\n",
    "    for name in os.listdir(\"data/meta/dim_reduce\"):\n",
    "        \n",
    "        if domain_bypass:\n",
    "            dom = domain_bypass\n",
    "        else:\n",
    "            dom = domain\n",
    "                    \n",
    "        if \"svd_{}_\".format(dom) in name:            \n",
    "            prev_vectorizer, svd = pickle.load(open(\"data/meta/dim_reduce/{}\".format(name), \"rb\"))    \n",
    "\n",
    "            if str(vectorizer.get_params) == str(prev_vectorizer):\n",
    "                print(\"Pre-Trained SVD found: {}\".format(name))\n",
    "                pca = svd\n",
    "                X = pca.transform(inp)\n",
    "                X = X[:,range(dim_out)]\n",
    "                if norm:\n",
    "                    X = normalize(X, axis=0)\n",
    "                return X, pca\n",
    "\n",
    "    pca = TruncatedSVD(n_components=master_, random_state=1)\n",
    "    pca.fit(inp)\n",
    "    \n",
    "    fn_ = \"data/meta/dim_reduce/svd_{}_{}_{}.bow\".format(domain, inp.shape[1], int(time.time()))\n",
    "    \n",
    "    pickle.dump((vectorizer.get_params, pca), open(fn_,\"wb\"))\n",
    "    print(\"Saving SVD: {}\".format(fn_))\n",
    "    \n",
    "    X = pca.transform(inp)\n",
    "    X = X[:,range(dim_out)]\n",
    "    if norm:\n",
    "        X = normalize(X, axis=0)\n",
    "    return X, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# print(input_data.shape)\n",
    "# # input_, pca = red_dim(input_data, 10 , domain_bypass='poseidon')\n",
    "# input_, pca = lda(input_data, 3) #, domain_bypass='poseidon')\n",
    "# print(input_.shape)\n",
    "# print(input_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# reduce dimension\n",
    "# Input: input, output_dimension \n",
    "# Out:   X, reduction_object\n",
    "#\n",
    "\n",
    "def lda(inp, out_dim=False, mid_dim=3000, domain_bypass=False, norm=True):\n",
    "    if domain_bypass:\n",
    "        dom = domain_bypass\n",
    "    else:\n",
    "        dom = domain\n",
    "                \n",
    "    mid_,_ = red_dim(inp, mid_dim, domain_bypass=dom)\n",
    "\n",
    "    # CHECK FOR PRE-TRAINED LDAs\n",
    "    for name in os.listdir(\"data/meta/dim_reduce\"):\n",
    "        if \"lda_{}_{}_\".format(dom, mid_dim) in name:\n",
    "            prev_vectorizer, lda = pickle.load(open(\"data/meta/dim_reduce/{}\".format(name), \"rb\"))    \n",
    "            if str(vectorizer.get_params) == str(prev_vectorizer):\n",
    "                print(\"Pre-Trained LDA found: {}\".format(name))\n",
    "                pca = lda\n",
    "                X = pca.transform(mid_)\n",
    "                if out_dim:\n",
    "                    X = X[:,range(out_dim)]\n",
    "                if norm:\n",
    "                    X = normalize(X, axis=0)\n",
    "                return X, lda\n",
    "\n",
    "    # TRAIN NEW LDA    \n",
    "    pca = LinearDiscriminantAnalysis()\n",
    "\n",
    "    X = pca.fit_transform(mid_, problem_numeric[:inp.shape[1]])\n",
    "    od = X.shape[1]\n",
    "\n",
    "    fn_ = \"data/meta/dim_reduce/lda_{}_{}_{}.bow\".format(domain,\n",
    "                                                            mid_dim,\n",
    "                                                            int(time.time()))\n",
    "    pickle.dump((vectorizer.get_params, pca), open(fn_,\"wb\"))\n",
    "    print(\"Saving LDA: {}\".format(fn_))\n",
    "    if out_dim:\n",
    "        X = X[:,range(out_dim)]\n",
    "    if norm:\n",
    "        X = normalize(X, axis=0)\n",
    "    return X, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\n",
    "\n",
    "# vect = CountVectorizer(tokenizer=LemmaTokenizer())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# TFIDF w/o using countvectorizer (Equivalent to CountVectorizer + TfidfTransformer)\n",
    "#\n",
    "def tfidf(inp):\n",
    "    global vectorizer\n",
    "    \n",
    "    vectorizer = HashingVectorizer(n_features=150000)\n",
    "#     vectorizer = HashingVectorizer(n_features=250000, non_negative=True)\n",
    "#     inp = vectorizer.fit_transform(inp)\n",
    "#     vectorizer = TfidfTransformer(sublinear_tf=False, use_idf=True)\n",
    "    \n",
    "#                                   token_pattern=u'\\\\w[A-Za-z]{3,10}\\\\b')\n",
    "    \n",
    "#     vectorizer = CountVectorizer(\n",
    "#                                 min_df=2, \n",
    "#                                 max_df = 0.5,\n",
    "#                                 token_pattern=u'\\\\w[A-Za-z]{3,10}\\\\b',\n",
    "#                                 ngram_range=(1,2)\n",
    "#                                 )\n",
    "    \n",
    "#     vectorizer = TfidfVectorizer(use_idf=True,\n",
    "#                                 stop_words='english',\n",
    "#                                 min_df = 3,\n",
    "#                                 max_df= 0.5,\n",
    "# #                                     vocabulary=voce,\n",
    "#                                 sublinear_tf=True)\n",
    "    \n",
    "    ans = vectorizer.fit_transform(inp)\n",
    "    return ans\n",
    "\n",
    "# input_data = tfidf(description[domain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# clf = list of estimators\n",
    "#\n",
    "\n",
    "def create_clf(inp_, domain_bypass=False, pre_trained=True):\n",
    "\n",
    "    # construct the estimators\n",
    "    clf = VotingClassifier([\n",
    "                            ('Support Vector Classifier (RBF)',SVC()),\n",
    "                            ('Naive Bayes Bernoulli',sklearn.naive_bayes.BernoulliNB()),\n",
    "                            ('Ridge Classifier',sklearn.linear_model.RidgeClassifier()),\n",
    "                            ('K-Nearest Neighbors',sklearn.neighbors.KNeighborsClassifier()),\n",
    "                            ('Random Forest Classifier', RandomForestClassifier()),\n",
    "        \n",
    "                            ('Support Vector Classifier (Linear)', SVC(C=0.01, \n",
    "                                                             decision_function_shape='ovo', \n",
    "                                                             gamma=1, \n",
    "                                                             kernel='linear')),\n",
    "        \n",
    "                            ('Stochastic Gradient Descent', SGDClassifier(alpha=0.001,\n",
    "                                                                        epsilon=0.01,\n",
    "                                                                        l1_ratio=0.1,\n",
    "                                                                        loss='hinge',\n",
    "                                                                        penalty='l1')),\n",
    "        \n",
    "                            ('Multi Layer Perceptron (SGD)', MLPClassifier(alpha=0.0001,\n",
    "                                                      solver='sgd')),\n",
    "                            \n",
    "                            ('Multi Layer Perceptron (Adam)', MLPClassifier(alpha=0.0001,\n",
    "                                                      solver='adam')),\n",
    "        \n",
    "                            ('Multi Layer Perceptron (Adam)',  MLPClassifier(solver='adam',\n",
    "                                                                            hidden_layer_sizes=(200,100)\n",
    "                                                                            ))\n",
    "                           ])\n",
    "\n",
    "    #\n",
    "    # Check if already trained\n",
    "    #\n",
    "    \n",
    "    if domain_bypass:\n",
    "        dom = domain_bypass\n",
    "    else:\n",
    "        dom = domain\n",
    "    \n",
    "    if pre_trained:\n",
    "        for name in os.listdir(\"data/meta/clf\"):\n",
    "            if \"{}_{}\".format(dom, inp_.shape[1]) in name:\n",
    "                prev_vector, tmp_clf = pickle.load(open(\"data/meta/clf/{}\".format(name), \"rb\"))\n",
    "                if str(vectorizer.get_params) == str(prev_vector):\n",
    "                    if str(tmp_clf.get_params) == str(clf.get_params):\n",
    "                        print(\"Pre-Trained CLF found:\" + name)\n",
    "                        return tmp_clf\n",
    "    \n",
    "    \n",
    "#     if pre_trained:\n",
    "#         for name in os.listdir(\"data/meta/clfs\"):\n",
    "#             if str(inp_.shape[1]) in name:\n",
    "#                 dom, data_shape, prev_vector, tmp_clf = pickle.load(open(\"data/meta/clfs/{}\".format(name), \"rb\"))\n",
    "\n",
    "#                 if domain == dom or domain_bypass == dom:\n",
    "#                     print(\":::{} & {}\".format(data_shape, inp_.shape))\n",
    "#                     if str(data_shape[1]) == str(inp_.shape[1]):\n",
    "#                         if str(vectorizer.get_params) == str(prev_vector):\n",
    "#                             if str(tmp_clf.get_params) == str(clf.get_params):\n",
    "#                                 print(\"Pre-Trained CLF found:\" + name)\n",
    "#                                 return tmp_clf\n",
    "    \n",
    "\n",
    "    #\n",
    "    # Train new - if none exist\n",
    "    #\n",
    "    X_train, X_test, y_train, y_test = train_test_split(inp_, problem_numeric, test_size=0.25, random_state=1)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    pickle.dump((vectorizer.get_params, clf), open(\"data/meta/clf/{}_{}_{}.clf\".format(domain, \n",
    "                                                                                        inp_.shape[1],\n",
    "                                                                                        int(time.time())), \n",
    "                                                   \"wb\"))\n",
    "    \n",
    "    print(\"Saving CLF as {}_{}_{}.clf\".format(domain, inp_.shape[1], int(time.time())))\n",
    "\n",
    "    return(clf)\n",
    "\n",
    "#\n",
    "# ---\n",
    "#\n",
    "\n",
    "# input_ = input_data\n",
    "# clf = create_clf(input_)\n",
    "# clfD = (clf, input_, \"none\", \"{} - Default\".format(input_.shape[1]))\n",
    "\n",
    "# clfs = [clfD]\n",
    "# #clfs = []\n",
    "# for x in tqdm([1000, 300, 5, 3]):\n",
    "#     input_, pca = red_dim(input_data, x)\n",
    "#     clf = create_clf(input_)\n",
    "#     clfs.append((clf, input_, pca, \"{}dim\".format(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Plot result of multiple classifiers (clfs)\n",
    "#\n",
    "\n",
    "\n",
    "def plot_clfs(clf_list, best_line=False):    \n",
    "    %matplotlib inline\n",
    "    best_score = 0\n",
    "    \n",
    "    fig = plt.figure(figsize=(25,7))\n",
    "    matplotlib.rcParams.update({'font.size': 27})\n",
    "\n",
    "    for ind, clf_tup in tqdm(enumerate(clf_list)):\n",
    "        clf_, input_, pca_, names = clf_tup\n",
    "        _, X_test, _, y_test = train_test_split(input_, problem_numeric, test_size=0.25, random_state=1)\n",
    "        \n",
    "        clf_count = np.arange(len(clf_.estimators))\n",
    "        clf_scores = [est.score(X_test, y_test) for est in clf_.estimators_]\n",
    "        \n",
    "        clf_names = [n[0] for n in clf_.estimators]\n",
    "        plt.bar(clf_count+((.8/len(clf_list)))*ind-.35, clf_scores, width=.8/(len(clf_list)), label=names)\n",
    "\n",
    "        plt.xticks(clf_count, clf_names)\n",
    "    \n",
    "        if max(clf_scores)>best_score:\n",
    "            best_score = max(clf_scores)\n",
    "        \n",
    "    if best_line:\n",
    "        plt.axhline(y=best_score)\n",
    "    \n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "#     plt.legend(ncol=3)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.title(\"{}\\n{}%\".format(domain, round(best_score*100, 1)))\n",
    "    plt.ylim([0,1])\n",
    "    plt.xlabel(\"Estimator\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    fig.show()\n",
    "    plt.show()\n",
    "\n",
    "# plot_clfs(clfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# F1 score measure\n",
    "#\n",
    "\n",
    "def eval_clf(clf_inp):    \n",
    "    %matplotlib inline\n",
    "    matplotlib.rcParams.update({'font.size': 16})\n",
    "\n",
    "    classifier, input_, pca_, names = clf_inp\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(input_, problem_numeric, test_size=0.25, random_state=1)\n",
    "\n",
    "    fig = plt.figure(figsize=(12,8))\n",
    "    clf_count = len(classifier.estimators)\n",
    "\n",
    "    for i, clfs_ in tqdm(enumerate(classifier.estimators_)):\n",
    "        y_pred = clfs_.predict(X_test)\n",
    "\n",
    "        scores = []\n",
    "#         scores.append(clfs_.score(X_test, y_test))\n",
    "        for avg in ['weighted', 'micro', 'macro']:\n",
    "            scores.append(f1_score(y_test, y_pred, labels=list(set(problem_numeric)), average=avg))\n",
    "\n",
    "        plt.bar(np.arange(3)+(.1*i)-0.25, scores, width=.1, label=classifier.estimators[i][0])\n",
    "        plt.title(names)\n",
    "\n",
    "    plt.xticks(range(3), ['F1 Weighted', 'F1 Micro', 'F1 Macro'])\n",
    "#     plt.legend(loc='upper left',ncol=2)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    fig.autofmt_xdate()\n",
    "    plt.ylim([0,1])\n",
    "    plt.xlabel(\"Evaluation method\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    fig.show()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# for clf_ in clfs:\n",
    "#     eval_clf(clf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Plot confussion matrix\n",
    "#\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(clf, normalize=False, estimator=None):    \n",
    "    %matplotlib inline\n",
    "    matplotlib.rcParams.update({'font.size': 16})\n",
    "\n",
    "    classes = sorted(list(set(problem)))\n",
    "    classifier, input_, pca_, names = clf\n",
    "    if estimator:\n",
    "        names = classifier.estimators[estimator][0] + \" : \" + names\n",
    "        classifier = classifier.estimators_[estimator]\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(input_, problem_numeric, test_size=0.25, random_state=1)\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    print(\"Accuracy:\",classifier.score(X_test, y_test))\n",
    " \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        title = 'Normalized confusion matrix \\n {}'.format(names)\n",
    "    else:\n",
    "        title = 'Confusion matrix \\n {}'.format(names)\n",
    "        \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    fig.set_size_inches(10, 10) #(22, 14)\n",
    "\n",
    "    cmap = plt.cm.Blues\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap, vmin=0., vmax=cm.max())\n",
    "    plt.title(title)\n",
    "#     plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    thresh = cm.max() * 0.85\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if cm[i, j] < 0.01:\n",
    "            continue\n",
    "        if normalize:\n",
    "            thresh = .64\n",
    "            val = str(round(cm[i, j]*100,2)).split(\".\")[0]+'%'\n",
    "        else:\n",
    "            val = cm[i, j]\n",
    "            \n",
    "        if cm[i, j] > thresh:\n",
    "            cl=\"white\"\n",
    "        else:\n",
    "            cl=\"black\"\n",
    "            \n",
    "        plt.text(j, i, val, horizontalalignment=\"center\", color=cl) #, alpha=cm[i,j]\n",
    "\n",
    "#     plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "    \n",
    "# plot_confusion_matrix(clfs[0])\n",
    "# plot_confusion_matrix(clfs[0], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Plot X (3D)  \n",
    "# Input: X (global)\n",
    "#\n",
    "\n",
    "def plot_data_3d(text=False, specific_cat=False):\n",
    "    %matplotlib inline\n",
    "    \n",
    "    matplotlib.rcParams.update({'font.size': 16})\n",
    "\n",
    "#     X3d,_ = red_dim(input_data, 3)\n",
    "    X3d,_ = lda(input_data)\n",
    "    \n",
    "    fig = plt.figure(1, figsize=(13, 10))\n",
    "    ax = Axes3D(fig)\n",
    "    y = problem\n",
    "    for name, label in zip(list(set(problem)), list(set(y))):  \n",
    "        if specific_cat!=False:\n",
    "            if not name in specific_cat:\n",
    "                continue\n",
    "                \n",
    "        ax.scatter(X3d[[label==t for t in y], 0], \n",
    "                  X3d[[label==t for t in y], 1],\n",
    "                  X3d[[label==t for t in y], 2], \n",
    "                   label=name, \n",
    "                   s=25,\n",
    "                   marker = 'o',\n",
    "#                    c='B',\n",
    "#                    marker = '+',\n",
    "                   alpha=1)\n",
    "   \n",
    "        if text:\n",
    "            ax.text3D(X3d[[label==t for t in y], 0].mean(),\n",
    "                      X3d[[label==t for t in y], 1].mean(),\n",
    "                      X3d[[label==t for t in y], 2].mean(), name)          \n",
    "\n",
    "    plt.title(domain.capitalize()+\"\\n\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "#     plt.legend(loc='upper left', ncol=2)\n",
    "    ax.set_xlabel('\\nPCA 0')\n",
    "    ax.set_ylabel('\\nPCA 1')\n",
    "    ax.set_zlabel('\\nPCA 2')\n",
    "    \n",
    "## Poseidon\n",
    "#     plt.xlim([10, 20])\n",
    "#     plt.ylim([-5, 5])\n",
    "## Alphabay  \n",
    "#     plt.xlim([-8, 4]) #9\n",
    "#     plt.ylim([-7, 20])\n",
    "#     ax.set_zlim([-21, 5])\n",
    "    \n",
    "    plt.show()\n",
    "    return(X3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot_data_3d(text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot_data_3d(x33, text=False, specific_cat='Weapons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Plot X (2D)  \n",
    "# Input: X2d (global)\n",
    "#\n",
    "\n",
    "\n",
    "def plot_data_2d(text=False, specific_cat=False):\n",
    "    %matplotlib inline\n",
    "    \n",
    "    matplotlib.rcParams.update({'font.size': 16})\n",
    "\n",
    "#     X2d,_ = red_dim(input_data, 2)\n",
    "    X2d,_ = lda(input_data)\n",
    "\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    y = problem\n",
    "    \n",
    "    for name in list(set(y)):\n",
    "        if specific_cat!=False:\n",
    "            if not name in specific_cat:\n",
    "                continue\n",
    "\n",
    "        plt.scatter(X2d[[name==t for t in y], 0],\n",
    "                    X2d[[name==t for t in y], 1],\n",
    "                    marker = '+',\n",
    "                    label=name, \n",
    "#                     c='r',\n",
    "                    s=25,\n",
    "                    alpha=1,\n",
    "                   )\n",
    "        if text:\n",
    "            plt.text(X2d[[name==t for t in y], 0].mean(),\n",
    "                     X2d[[name==t for t in y], 1].mean(),\n",
    "                     name)\n",
    "    plt.title(domain.capitalize())\n",
    "    plt.xlabel(\"PCA 0\")\n",
    "    plt.ylabel(\"PCA 1\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "#     plt.xlim([0, 125])\n",
    "#     plt.ylim([-20, 80])\n",
    "#     plt.xlim([-.025, .025])\n",
    "#     plt.ylim([-.025, .1])\n",
    "    \n",
    "    plt.show()\n",
    "    return X2d\n",
    "\n",
    "# plot_data_2d()\n",
    "\n",
    "# for x in set(category[\"alphabay\"]):\n",
    "#     print(x)\n",
    "#     plot_data_2d(text=False, specific_cat=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# data2 = plot_data_2d(text=False)\n",
    "# data2 = plot_data_2d(text=False, specific_cat='Weapons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Scree plot\n",
    "#\n",
    "\n",
    "def scree(dim=1000, threshold=.9):\n",
    "    \n",
    "    if dim >= input_data.shape[1]:\n",
    "        dim = int(input_data.shape[1]/2)\n",
    "        \n",
    "    xRed_, pca2 = red_dim(input_data, dim)\n",
    "\n",
    "\n",
    "    plt.ylim(0)\n",
    "#     plt.text(1,0.85,\"Number of components\\n\"+str(input_data.shape[1]))\n",
    "    var_rat = np.cumsum(pca2.explained_variance_ratio_)\n",
    "    var = np.cumsum(pca2.explained_variance_)\n",
    "    var = [float(i)/pca2.explained_variance_[0] for i in pca2.explained_variance_]\n",
    "\n",
    "    %matplotlib inline\n",
    "    matplotlib.rcParams.update({'font.size': 16})\n",
    "    plt.ylabel(\"Variance\")\n",
    "    plt.xlabel(\"Components\")\n",
    "    plt.title(\"{}\\n{} Features\".format(domain, input_data.shape[1]))\n",
    "    plt.plot(var_rat, label=\"Cumulative variance ratio\")\n",
    "    plt.plot(var, label=\"Normalized variance\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.ylim([0,1])\n",
    "    plt.show()\n",
    "    \n",
    "    for i, x in enumerate(var_rat):\n",
    "        if x > threshold:\n",
    "            return i\n",
    "    return dim\n",
    "        \n",
    "# scree(100, .95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Make same domain etc.\n",
    "#\n",
    "\n",
    "# description[\"poseidon\"].append('Services sad sd')\n",
    "# description[\"poseidon\"].append('Jewels&Gold sad sd')\n",
    "# category[\"poseidon\"].append('Services')\n",
    "# category[\"poseidon\"].append('Jewels&Gold')\n",
    "\n",
    "pprint(len(set(category[\"poseidon\"])))\n",
    "pprint(len(set(category[\"alphabay\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 3688\n",
      "Features: 250000\n"
     ]
    }
   ],
   "source": [
    "domain = \"poseidon\"\n",
    "problem = category[domain]\n",
    "input_data = tfidf(description[domain])\n",
    "problem_numeric = [sorted(list(set(category[domain]))).index(x) for x in problem]\n",
    "\n",
    "print(\"Samples:\", len(problem))\n",
    "print(\"Features:\", input_data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 3688\n",
      "Features: 150000\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-1be37928d8ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m#     clfs.append((clf, input_, pca, \"{}dim\".format(x)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, domain_bypass='poseidon')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, domain_bypass='poseidon')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mclfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{}dim\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"3000 Intermediate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-5850b299f646>\u001b[0m in \u001b[0;36mlda\u001b[0;34m(inp, out_dim, mid_dim, domain_bypass, norm)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mdom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdomain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmid_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mred_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmid_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdomain_bypass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# CHECK FOR PRE-TRAINED LDAs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-1b5f168499c3>\u001b[0m in \u001b[0;36mred_dim\u001b[0;34m(inp, dim_out, domain_bypass, norm)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTruncatedSVD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaster_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mfn_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data/meta/dim_reduce/svd_{}_{}_{}.bow\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/decomposition/truncated_svd.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtransformer\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \"\"\"\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/decomposition/truncated_svd.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    171\u001b[0m             U, Sigma, VT = randomized_svd(X, self.n_components,\n\u001b[1;32m    172\u001b[0m                                           \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                                           random_state=random_state)\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unknown algorithm %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36mrandomized_svd\u001b[0;34m(M, n_components, n_oversamples, n_iter, power_iteration_normalizer, transpose, flip_sign, random_state)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     Q = randomized_range_finder(M, n_random, n_iter,\n\u001b[0;32m--> 364\u001b[0;31m                                 power_iteration_normalizer, random_state)\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;31m# project M to the (k + p) dimensional space using the basis vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36mrandomized_range_finder\u001b[0;34m(A, size, n_iter, power_iteration_normalizer, random_state)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpower_iteration_normalizer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'LU'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpermute_l\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m             \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpermute_l\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpower_iteration_normalizer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'QR'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/scipy/linalg/decomp_lu.py\u001b[0m in \u001b[0;36mlu\u001b[0;34m(a, permute_l, overwrite_a, check_finite)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0moverwrite_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverwrite_a\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_datacopied\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0mflu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_flinalg_funcs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpermute_l\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpermute_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverwrite_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         raise ValueError('illegal value in %d-th argument of '\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##\n",
    "## Problem and target \n",
    "##\n",
    "\n",
    "domain = \"poseidon\"\n",
    "problem = category[domain]\n",
    "input_data = tfidf(description[domain])\n",
    "problem_numeric = [sorted(list(set(category[domain]))).index(x) for x in problem]\n",
    "\n",
    "print(\"Samples:\", len(problem))\n",
    "print(\"Features:\", input_data.shape[1])\n",
    "\n",
    "\n",
    "##\n",
    "## Visualize data\n",
    "##\n",
    "# plot_data_3d()\n",
    "# plot_data_2d()\n",
    "\n",
    "##\n",
    "## Check BOW-model feature restraints\n",
    "##\n",
    "\n",
    "# feat_impact(domain, start=10, stop=2500, step=100)\n",
    "\n",
    "##\n",
    "## Check when exp. var > treshold (nm of useful features) \n",
    "##\n",
    "\n",
    "# dims = scree(3000, .99)\n",
    "# dims = 500\n",
    "\n",
    "##\n",
    "## Train models \n",
    "##\n",
    "\n",
    "# clf = create_clf(input_data)\n",
    "# clfD = (clf, input_data, \"none\", \"{} - Default\".format(input_data.shape[1]))\n",
    "# clfs = [clfD]\n",
    "\n",
    "clfs = []\n",
    "# for x in tqdm([int(dims), int(dims/2)]):\n",
    "# #     input_, pca = red_dim(input_data, x , domain_bypass='poseidon')\n",
    "#     input_, pca = lda(input_data) #, domain_bypass='poseidon')\n",
    "#     clf = create_clf(input_) #, domain_bypass='poseidon')\n",
    "#     clfs.append((clf, input_, pca, \"{}dim\".format(x)))\n",
    "\n",
    "input_, pca = lda(input_data) #, domain_bypass='poseidon')\n",
    "clf = create_clf(input_) #, domain_bypass='poseidon')\n",
    "clfs.append((clf, input_, pca, \"{}dim\".format(\"3000 Intermediate\")))\n",
    "\n",
    "##\n",
    "## Display result\n",
    "##\n",
    "\n",
    "plot_clfs(clfs, best_line=True)\n",
    "\n",
    "\n",
    "##\n",
    "## Result F1 & Confusion matrix\n",
    "##\n",
    "\n",
    "for clf_ in clfs:\n",
    "    eval_clf(clf_)\n",
    "    plot_confusion_matrix(clf_, normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clfs[-1], normalize=True, estimator=-1)\n",
    "plot_confusion_matrix(clfs[-1], normalize=False, estimator=-1)\n",
    "\n",
    "plot_confusion_matrix(clfs[0], normalize=True, estimator=-1)\n",
    "plot_confusion_matrix(clfs[0], normalize=False, estimator=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
